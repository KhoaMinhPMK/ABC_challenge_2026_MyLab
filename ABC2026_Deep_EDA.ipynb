{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b41ec210",
   "metadata": {},
   "source": [
    "# üî¨ ABC2026 CHALLENGE - DEEP EDA & FEATURE ENGINEERING\n",
    "---\n",
    "**Notebook n√†y t·∫≠p trung v√†o ph√¢n t√≠ch chuy√™n s√¢u (Deep EDA) v√† x·ª≠ l√Ω d·ªØ li·ªáu (Feature Engineering) cho b√†i to√°n ƒë·ªãnh v·ªã trong nh√† (Indoor Localization) d·ª±a tr√™n BLE.**\n",
    "\n",
    "### üéØ M·ª•c ti√™u:\n",
    "1.  **Data Loading & Alignment**: Load d·ªØ li·ªáu t·ª´ local, ƒë·ªìng b·ªô th·ªùi gian gi·ªØa BLE v√† Label.\n",
    "2.  **Deep EDA (Raw Data)**:\n",
    "    *   Ph√¢n t√≠ch m·∫•t c√¢n b·∫±ng l·ªõp (Class Imbalance) & Lorenz Curve.\n",
    "    *   ƒê√°nh gi√° ƒë·ªô ph·ªß (Coverage) v√† ƒë·ªô tin c·∫≠y (Reliability) c·ªßa t·ª´ng Beacon.\n",
    "    *   Ph√¢n t√≠ch ch·∫•t l∆∞·ª£ng t√≠n hi·ªáu (SNR, Stability Index).\n",
    "3.  **Feature Engineering**:\n",
    "    *   √Åp d·ª•ng Sliding Window ƒë·ªÉ kh·ª≠ nhi·ªÖu v√† x·ª≠ l√Ω d·ªØ li·ªáu th∆∞a (Sparsity).\n",
    "4.  **Deep EDA (Features)**:\n",
    "    *   Ph√¢n t√≠ch t∆∞∆°ng quan (Correlation) gi·ªØa c√°c Beacons.\n",
    "    *   ƒê√°nh gi√° kh·∫£ nƒÉng ph√¢n t√°ch l·ªõp (Separability) b·∫±ng PCA v√† t-SNE.\n",
    "\n",
    "### üìÇ C·∫•u tr√∫c d·ªØ li·ªáu:\n",
    "*   **Input**: `E:\\project\\ABC2026\\ABC2026 Sozolab Challenge\\Dataset`\n",
    "*   **Output**: C√°c bi·ªÉu ƒë·ªì ph√¢n t√≠ch v√† file summary JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a87b7968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Setup & Data Loading (Colab-ready)\n",
    "# T·∫£i data.zip t·ª´ link cung c·∫•p v√† gi·∫£i n√©n ƒë·ªÉ c√≥ c·∫•u tr√∫c nh∆∞ local.\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import zipfile\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "DATA_URL = \"https://bkuteam.site/data.zip\"\n",
    "BASE_DIR = Path(\"/content/ABC2026\")\n",
    "ZIP_PATH = BASE_DIR / \"data.zip\"\n",
    "BASE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DATA_ROOT = BASE_DIR / \"ABC2026 Sozolab Challenge\"\n",
    "DATASET_DIR = DATA_ROOT / \"Dataset\"\n",
    "DATA_READY = DATASET_DIR.exists() and any(DATASET_DIR.glob(\"*.csv\"))\n",
    "\n",
    "if DATA_READY:\n",
    "    print(\"Data ƒë√£ c√≥ s·∫µn, b·ªè qua b∆∞·ªõc t·∫£i.\")\n",
    "else:\n",
    "    print(\"Downloading data.zip...\")\n",
    "    resp = requests.get(DATA_URL, stream=True)\n",
    "    resp.raise_for_status()\n",
    "    with open(ZIP_PATH, \"wb\") as f:\n",
    "        for chunk in resp.iter_content(chunk_size=8192):\n",
    "            if chunk:\n",
    "                f.write(chunk)\n",
    "    print(\"Extracting...\")\n",
    "    with zipfile.ZipFile(ZIP_PATH, \"r\") as zf:\n",
    "        zf.extractall(BASE_DIR)\n",
    "    DATA_READY = DATASET_DIR.exists() and any(DATASET_DIR.glob(\"*.csv\"))\n",
    "    if DATA_READY:\n",
    "        print(\"Gi·∫£i n√©n xong, d·ªØ li·ªáu s·∫µn s√†ng.\")\n",
    "    else:\n",
    "        raise FileNotFoundError(\"Gi·∫£i n√©n xong nh∆∞ng kh√¥ng th·∫•y file CSV trong Dataset.\")\n",
    "\n",
    "DATA_PATH = str(DATASET_DIR)\n",
    "OUTPUT_PATH = str(DATA_ROOT)\n",
    "\n",
    "# Mapping 25 Beacons\n",
    "MAC_LIST = [\n",
    "    'F7:7F:78:76:7E:F3', 'C6:CD:5E:3D:2F:BB', 'D6:F4:3A:79:74:63', 'C9:17:55:E2:3E:0E', 'CA:60:AB:EE:EC:7F',\n",
    "    'D6:51:7F:AB:0E:29', 'CC:54:33:F6:A7:90', 'EB:20:56:87:04:5A', 'EE:E7:46:DC:19:6F', 'C8:5B:BF:37:07:A0',\n",
    "    'D7:26:F6:A3:44:D2', 'DD:83:B0:27:FD:36', 'E5:CD:4A:36:87:06', 'DC:22:B8:17:4E:B5', 'EA:09:20:80:D6:44',\n",
    "    'E6:99:D1:EC:C6:81', 'F6:DA:97:C7:D5:28', 'EA:66:A1:12:2C:F4', 'C9:EA:57:8B:0F:80', 'D6:7C:1D:2C:2A:0A',\n",
    "    'DA:E1:70:5F:44:97', 'DD:10:10:F6:4F:27', 'E6:F3:93:A8:9E:22', 'E6:60:05:1F:88:F9', 'D4:33:FD:F4:C2:A8'\n",
    "]\n",
    "BEACON_IDS = [str(i) for i in range(1, 26)]\n",
    "MAC_TO_BEACON = dict(zip(MAC_LIST, BEACON_IDS))\n",
    "\n",
    "print(f\"Data Path: {DATA_PATH}\")\n",
    "if not os.path.exists(DATA_PATH):\n",
    "    raise FileNotFoundError(f\"Path not found: {DATA_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8300985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1b: Plot logging helper (ƒë·∫∑t t√™n + l∆∞u metadata cho m·ªói bi·ªÉu ƒë·ªì)\n",
    "# Quy t·∫Øc: m·ªçi bi·ªÉu ƒë·ªì ph·∫£i ƒë·∫∑t t√™n, log tham s·ªë v√† in th√¥ng tin ƒë·∫ßu v√†o.\n",
    "PLOT_REGISTRY = []\n",
    "PLOT_META_PATH = os.path.join(OUTPUT_PATH, \"plot_metadata.json\")\n",
    "\n",
    "\n",
    "def log_plot(name: str, description: str = \"\", params: dict | None = None, data_notes: dict | None = None):\n",
    "    \"\"\"Ghi log metadata cho bi·ªÉu ƒë·ªì, in ra v√† l∆∞u JSON ƒë∆°n gi·∫£n.\"\"\"\n",
    "    meta = {\n",
    "        \"name\": name,\n",
    "        \"description\": description,\n",
    "        \"params\": params or {},\n",
    "        \"data_notes\": data_notes or {},\n",
    "        \"timestamp\": pd.Timestamp.now().isoformat(),\n",
    "    }\n",
    "    PLOT_REGISTRY.append(meta)\n",
    "    print(f\"[PLOT LOG] {name}\")\n",
    "    print(json.dumps(meta, indent=2, ensure_ascii=False))\n",
    "    try:\n",
    "        with open(PLOT_META_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(PLOT_REGISTRY, f, ensure_ascii=False, indent=2)\n",
    "        print(f\"[PLOT LOG] ƒê√£ l∆∞u: {PLOT_META_PATH}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[C·∫¢NH B√ÅO] Kh√¥ng l∆∞u ƒë∆∞·ª£c plot metadata: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bb6aa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Load Files & Align Data\n",
    "# Load BLE (User 90) and Label (User 97 Location)\n",
    "\n",
    "# 1. Find Files\n",
    "ble_files = []\n",
    "label_file = None\n",
    "ble_folder = os.path.join(DATA_PATH, \"BLE Data\")\n",
    "\n",
    "if os.path.exists(ble_folder):\n",
    "    for f in os.listdir(ble_folder):\n",
    "        if f.endswith(\".csv\") and \"user-ble-id_90\" in f:\n",
    "            ble_files.append(os.path.join(ble_folder, f))\n",
    "\n",
    "for f in os.listdir(DATA_PATH):\n",
    "    if \"label\" in f.lower() and \"train\" in f.lower() and f.endswith(\".csv\"):\n",
    "        label_file = os.path.join(DATA_PATH, f)\n",
    "\n",
    "if not ble_files:\n",
    "    raise ValueError(\"No BLE files found.\")\n",
    "if not label_file:\n",
    "    raise ValueError(\"No Label file found.\")\n",
    "\n",
    "print(f\"Found {len(ble_files)} BLE files and Label file: {os.path.basename(label_file)}\")\n",
    "\n",
    "# 2. Load BLE\n",
    "ble_dfs = []\n",
    "for f in tqdm(ble_files, desc=\"Loading BLE\"):\n",
    "    try:\n",
    "        df = pd.read_csv(f, header=None, names=['user_id', 'timestamp', 'scan_content', 'mac address', 'RSSI', 'tx_power'])\n",
    "        df = df[df['mac address'].isin(MAC_LIST)].copy()\n",
    "        if not df.empty:\n",
    "            df['beacon_id'] = df['mac address'].map(MAC_TO_BEACON)\n",
    "            ble_dfs.append(df[['timestamp', 'beacon_id', 'RSSI']])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "df_ble = pd.concat(ble_dfs, ignore_index=True)\n",
    "df_ble['datetime'] = pd.to_datetime(df_ble['timestamp'], utc=True).dt.tz_convert('Asia/Tokyo')\n",
    "df_ble = df_ble.sort_values('datetime')\n",
    "\n",
    "# 3. Load Label\n",
    "df_lbl = pd.read_csv(label_file)\n",
    "df_lbl = df_lbl[(df_lbl['user_id'] == 97) & (df_lbl['activity'] == 'Location')].copy()\n",
    "for col in ['started_at', 'finished_at']:\n",
    "    df_lbl[col] = pd.to_datetime(df_lbl[col])\n",
    "    if df_lbl[col].dt.tz is None:\n",
    "        df_lbl[col] = df_lbl[col].dt.tz_localize('Asia/Tokyo')\n",
    "    else:\n",
    "        df_lbl[col] = df_lbl[col].dt.tz_convert('Asia/Tokyo')\n",
    "df_lbl = df_lbl.sort_values('started_at')\n",
    "\n",
    "# 4. Align\n",
    "print(\"Aligning Data...\")\n",
    "labeled_data = []\n",
    "for _, row in tqdm(df_lbl.iterrows(), total=len(df_lbl), desc=\"Aligning\"):\n",
    "    mask = (df_ble['datetime'] >= row['started_at']) & (df_ble['datetime'] <= row['finished_at'])\n",
    "    subset = df_ble[mask].copy()\n",
    "    if not subset.empty:\n",
    "        subset['location'] = row['room']\n",
    "        labeled_data.append(subset)\n",
    "\n",
    "if labeled_data:\n",
    "    df_final = pd.concat(labeled_data, ignore_index=True)\n",
    "\n",
    "    raw_summary = {\n",
    "        'total_samples': len(df_final),\n",
    "        'time_range': {'start': str(df_final['datetime'].min()), 'end': str(df_final['datetime'].max())},\n",
    "        'num_locations': int(df_final['location'].nunique()),\n",
    "        'num_beacons': int(df_final['beacon_id'].nunique()),\n",
    "        'locations': df_final['location'].value_counts().to_dict()\n",
    "    }\n",
    "    with open(os.path.join(OUTPUT_PATH, 'data_summary_raw.json'), 'w', encoding='utf-8') as f:\n",
    "        json.dump(raw_summary, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    print(f\"Raw Dataset Shape: {df_final.shape}\")\n",
    "    print(f\"   Time Range: {df_final['datetime'].min()} -> {df_final['datetime'].max()}\")\n",
    "    print(f\"   Locations: {df_final['location'].nunique()}\")\n",
    "    print(\"   Saved: data_summary_raw.json\")\n",
    "    display(df_final.head())\n",
    "else:\n",
    "    raise ValueError(\"Alignment failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd820672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Data Prep for EDA (no plots)\n",
    "# T√≠nh to√°n tr∆∞·ªõc: ph√¢n b·ªë m·∫´u, lorenz, ƒë·ªô ph·ªß, fingerprint, reliability.\n",
    "\n",
    "if 'df_final' in locals():\n",
    "    # Counts\n",
    "    loc_counts = df_final['location'].value_counts().sort_values(ascending=False)\n",
    "    beacon_counts = df_final['beacon_id'].value_counts().sort_index()\n",
    "\n",
    "    # Sparsity matrix (coverage % per location-beacon)\n",
    "    sparsity_data = []\n",
    "    for loc in df_final['location'].unique():\n",
    "        df_loc = df_final[df_final['location'] == loc]\n",
    "        total = len(df_loc)\n",
    "        for b in BEACON_IDS:\n",
    "            cnt = (df_loc['beacon_id'] == b).sum()\n",
    "            coverage = (cnt / total * 100) if total > 0 else 0\n",
    "            sparsity_data.append({'location': loc, 'beacon_id': b, 'coverage_pct': coverage})\n",
    "    df_sparsity = pd.DataFrame(sparsity_data)\n",
    "    sparsity_pivot = df_sparsity.pivot(index='location', columns='beacon_id', values='coverage_pct')\n",
    "    sparsity_pivot = sparsity_pivot[sorted(sparsity_pivot.columns, key=lambda x: int(x))]\n",
    "\n",
    "    # RSSI fingerprint\n",
    "    rssi_pivot = df_final.pivot_table(index='location', columns='beacon_id', values='RSSI', aggfunc='mean')\n",
    "    rssi_pivot = rssi_pivot[sorted(rssi_pivot.columns, key=lambda x: int(x))]\n",
    "    rssi_std_pivot = df_final.pivot_table(index='location', columns='beacon_id', values='RSSI', aggfunc='std')\n",
    "    rssi_std_pivot = rssi_std_pivot[sorted(rssi_std_pivot.columns, key=lambda x: int(x))]\n",
    "\n",
    "    # Reliability\n",
    "    reliability_rows = []\n",
    "    for b in BEACON_IDS:\n",
    "        avg_cov = sparsity_pivot[b].mean()\n",
    "        avg_rssi = df_final[df_final['beacon_id'] == b]['RSSI'].mean()\n",
    "        rssi_norm = ((avg_rssi + 100) / 70) * 100 if avg_rssi > -100 else 0\n",
    "        score = (avg_cov + rssi_norm) / 2\n",
    "        reliability_rows.append({'beacon_id': b, 'reliability_score': score, 'coverage_pct': avg_cov, 'avg_rssi': avg_rssi})\n",
    "    df_reliability = pd.DataFrame(reliability_rows).sort_values('reliability_score', ascending=False)\n",
    "\n",
    "    # Lorenz/Gini\n",
    "    loc_sorted = loc_counts.sort_values()\n",
    "    cumsum = np.cumsum(loc_sorted.values)\n",
    "    lorenz_y = cumsum / cumsum[-1]\n",
    "    lorenz_x = np.arange(1, len(lorenz_y) + 1) / len(lorenz_y)\n",
    "    gini_coeff = 1 - 2 * np.trapz(lorenz_y, lorenz_x)\n",
    "\n",
    "    # Print key numbers for downstream plots\n",
    "    print(\"DATA PREP SUMMARY\")\n",
    "    print(f\"Samples: {len(df_final):,}; Locations: {df_final['location'].nunique()}; Beacons seen: {df_final['beacon_id'].nunique()}/25\")\n",
    "    print(f\"Max/Min samples per location: {loc_counts.max():,} / {loc_counts.min():,}; Ratio: {loc_counts.max()/loc_counts.min():.2f}x\")\n",
    "    print(f\"Gini: {gini_coeff:.3f}\")\n",
    "    print(f\"Coverage <10% beacons: {(df_reliability['coverage_pct'] < 10).sum()}/25\")\n",
    "    print(f\"Zero-coverage pairs: {(sparsity_pivot == 0).sum().sum()} of {sparsity_pivot.size}\")\n",
    "else:\n",
    "    print(\"Run Cell 2 first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39840a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Plot - Location Sample Distribution (Class Imbalance)\n",
    "if 'loc_counts' in globals():\n",
    "    plot_name = \"Location Sample Distribution\"\n",
    "    plot_params = {\n",
    "        \"loc_count_max\": int(loc_counts.max()),\n",
    "        \"loc_count_min\": int(loc_counts.min()),\n",
    "        \"locations\": int(len(loc_counts)),\n",
    "        \"mean\": float(loc_counts.mean()),\n",
    "    }\n",
    "    data_notes = {\n",
    "        \"top5_locations\": {k: int(v) for k, v in loc_counts.head(5).to_dict().items()},\n",
    "        \"bottom5_locations\": {k: int(v) for k, v in loc_counts.tail(5).to_dict().items()},\n",
    "    }\n",
    "    print(\"Params:\", plot_params)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x=loc_counts.index, y=loc_counts.values, palette=\"viridis\")\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.title(plot_name)\n",
    "    plt.ylabel(\"Sample Count\")\n",
    "    plt.axhline(loc_counts.mean(), color='red', linestyle='--', label=f\"Mean: {loc_counts.mean():.0f}\")\n",
    "    plt.legend()\n",
    "    plt.gcf().subplots_adjust(bottom=0.28)\n",
    "    plt.tight_layout()\n",
    "    log_plot(\n",
    "        name=plot_name,\n",
    "        description=\"Ph√¢n b·ªë m·∫´u theo location (ƒë√°nh gi√° imbalance)\",\n",
    "        params=plot_params,\n",
    "        data_notes=data_notes,\n",
    "    )\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Run Cell 3 first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a0b729d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Plot - Lorenz Curve (Class Imbalance)\n",
    "if 'lorenz_x' in globals() and 'lorenz_y' in globals():\n",
    "    plot_name = f\"Lorenz Curve (Gini={gini_coeff:.3f})\"\n",
    "    plot_params = {\"gini\": float(gini_coeff), \"points\": int(len(lorenz_x))}\n",
    "    data_notes = {\n",
    "        \"lorenz_start\": float(lorenz_y[0]) if len(lorenz_y) > 0 else None,\n",
    "        \"lorenz_end\": float(lorenz_y[-1]) if len(lorenz_y) > 0 else None,\n",
    "    }\n",
    "    print(\"Params:\", plot_params)\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    plt.plot(lorenz_x, lorenz_y, marker='o', markersize=3, label='Lorenz Curve', color='blue')\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Perfect Equality')\n",
    "    plt.fill_between(lorenz_x, lorenz_y, alpha=0.2, color='blue')\n",
    "    plt.xlabel(\"Cumulative % Locations\")\n",
    "    plt.ylabel(\"Cumulative % Samples\")\n",
    "    plt.title(plot_name)\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    log_plot(\n",
    "        name=plot_name,\n",
    "        description=\"ƒê·ªô m·∫•t c√¢n b·∫±ng m·∫´u qua ƒë∆∞·ªùng Lorenz\",\n",
    "        params=plot_params,\n",
    "        data_notes=data_notes,\n",
    "    )\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Run Cell 3 first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4cbe8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Plot - Beacon Reliability Score\n",
    "if 'df_reliability' in globals():\n",
    "    plot_name = \"Beacon Reliability Score\"\n",
    "    top5_scores = df_reliability['reliability_score'].head(5).round(2).tolist()\n",
    "    bottom5_scores = df_reliability['reliability_score'].tail(5).round(2).tolist()\n",
    "    plot_params = {\n",
    "        \"top5\": top5_scores,\n",
    "        \"bottom5\": bottom5_scores,\n",
    "        \"coverage_mean\": float(df_reliability['coverage_pct'].mean()),\n",
    "    }\n",
    "    data_notes = {\n",
    "        \"best_beacon\": str(df_reliability.iloc[0]['beacon_id']),\n",
    "        \"best_score\": float(df_reliability.iloc[0]['reliability_score']),\n",
    "        \"worst_beacon\": str(df_reliability.iloc[-1]['beacon_id']),\n",
    "        \"worst_score\": float(df_reliability.iloc[-1]['reliability_score']),\n",
    "    }\n",
    "    print(\"Params:\", plot_params)\n",
    "    plt.figure(figsize=(7, 6))\n",
    "    sns.barplot(y=df_reliability['beacon_id'].astype(int), x=df_reliability['reliability_score'], color='tab:red')\n",
    "    plt.xlabel(\"Reliability Score (0-100)\")\n",
    "    plt.ylabel(\"Beacon ID\")\n",
    "    plt.title(plot_name)\n",
    "    plt.tight_layout()\n",
    "    log_plot(\n",
    "        name=plot_name,\n",
    "        description=\"Ch·ªâ s·ªë ƒë·ªô tin c·∫≠y beacon (coverage + RSSI)\",\n",
    "        params=plot_params,\n",
    "        data_notes=data_notes,\n",
    "    )\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Run Cell 3 first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f953fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Plot - Beacon Coverage Heatmap (% of samples)\n",
    "if 'sparsity_pivot' in globals():\n",
    "    plot_name = \"Beacon Coverage by Location (%)\"\n",
    "    coverage_mean = float(sparsity_pivot.mean(axis=1).mean())\n",
    "    zero_pairs = int((sparsity_pivot == 0).sum().sum())\n",
    "    total_pairs = int(sparsity_pivot.size)\n",
    "    plot_params = {\"coverage_mean_pct\": coverage_mean, \"zero_pairs\": zero_pairs, \"total_pairs\": total_pairs}\n",
    "    data_notes = {\n",
    "        \"coverage_mean_by_location\": sparsity_pivot.mean(axis=1).round(2).head(5).to_dict(),\n",
    "    }\n",
    "    print(\"Params:\", plot_params)\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    sns.heatmap(sparsity_pivot, cmap=\"YlGnBu\", vmin=0, vmax=100, linewidths=0.3, linecolor='white', cbar_kws={\"shrink\": 0.8})\n",
    "    plt.xlabel(\"Beacon ID\")\n",
    "    plt.ylabel(\"Location\")\n",
    "    plt.title(plot_name)\n",
    "    plt.tight_layout()\n",
    "    log_plot(\n",
    "        name=plot_name,\n",
    "        description=\"Heatmap ƒë·ªô ph·ªß beacon theo location (t·ª∑ l·ªá % m·∫´u)\",\n",
    "        params=plot_params,\n",
    "        data_notes=data_notes,\n",
    "    )\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Run Cell 3 first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ccc4bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Plot - Mean RSSI Fingerprint\n",
    "if 'rssi_pivot' in globals():\n",
    "    plot_name = \"Mean RSSI by Location-Beacon\"\n",
    "    plot_params = {\n",
    "        \"rssi_mean\": float(df_final['RSSI'].mean()),\n",
    "        \"rssi_std\": float(df_final['RSSI'].std()),\n",
    "    }\n",
    "    data_notes = {\n",
    "        \"locations_sample\": rssi_pivot.head(3).mean(axis=1).round(2).to_dict(),\n",
    "    }\n",
    "    print(\"Params:\", plot_params)\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    sns.heatmap(rssi_pivot.fillna(-100), cmap=\"RdYlGn\", vmin=-100, vmax=-30, linewidths=0.3, linecolor='white', cbar_kws={\"shrink\": 0.8})\n",
    "    plt.xlabel(\"Beacon ID\")\n",
    "    plt.ylabel(\"Location\")\n",
    "    plt.title(plot_name)\n",
    "    plt.tight_layout()\n",
    "    log_plot(\n",
    "        name=plot_name,\n",
    "        description=\"Fingerprint RSSI trung b√¨nh theo location-beacon\",\n",
    "        params=plot_params,\n",
    "        data_notes=data_notes,\n",
    "    )\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Run Cell 3 first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60871b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Plot - RSSI Stability (Std Dev)\n",
    "if 'rssi_std_pivot' in globals():\n",
    "    mean_std = rssi_std_pivot.mean(axis=1)\n",
    "    plot_name = \"RSSI Std Dev by Location-Beacon\"\n",
    "    plot_params = {\n",
    "        \"min_std\": float(mean_std.min()),\n",
    "        \"min_loc\": mean_std.idxmin(),\n",
    "        \"max_std\": float(mean_std.max()),\n",
    "        \"max_loc\": mean_std.idxmax(),\n",
    "    }\n",
    "    data_notes = {\n",
    "        \"sample_std_by_location\": mean_std.head(5).round(2).to_dict(),\n",
    "    }\n",
    "    print(\"Params:\", plot_params)\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    sns.heatmap(rssi_std_pivot.fillna(0), cmap=\"Reds\", vmin=0, vmax=15, linewidths=0.3, linecolor='white', cbar_kws={\"shrink\": 0.8})\n",
    "    plt.xlabel(\"Beacon ID\")\n",
    "    plt.ylabel(\"Location\")\n",
    "    plt.title(plot_name)\n",
    "    plt.tight_layout()\n",
    "    log_plot(\n",
    "        name=plot_name,\n",
    "        description=\"ƒê·ªô ·ªïn ƒë·ªãnh RSSI (ƒë·ªô l·ªách chu·∫©n) theo location-beacon\",\n",
    "        params=plot_params,\n",
    "        data_notes=data_notes,\n",
    "    )\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Run Cell 3 first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0688e8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Plot - Beacon Detection Frequency\n",
    "if 'beacon_counts' in globals():\n",
    "    plot_name = \"Beacon Detection Frequency\"\n",
    "    plot_params = {\n",
    "        \"median_freq\": float(beacon_counts.median()),\n",
    "        \"max_freq\": int(beacon_counts.max()),\n",
    "        \"min_freq\": int(beacon_counts.min()),\n",
    "    }\n",
    "    data_notes = {\n",
    "        \"top5_beacons\": {int(k): int(v) for k, v in beacon_counts.head(5).to_dict().items()},\n",
    "    }\n",
    "    print(\"Params:\", plot_params)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.barplot(x=beacon_counts.index.astype(int), y=beacon_counts.values, color='teal')\n",
    "    plt.axhline(beacon_counts.median(), color='red', linestyle='--', label='Median')\n",
    "    plt.xlabel(\"Beacon ID\")\n",
    "    plt.ylabel(\"Detections\")\n",
    "    plt.title(plot_name)\n",
    "    plt.legend()\n",
    "    plt.gcf().subplots_adjust(bottom=0.18)\n",
    "    plt.tight_layout()\n",
    "    log_plot(\n",
    "        name=plot_name,\n",
    "        description=\"T·∫ßn su·∫•t ph√°t hi·ªán beacon\",\n",
    "        params=plot_params,\n",
    "        data_notes=data_notes,\n",
    "    )\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Run Cell 3 first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad4db18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Plot - Sample Distribution Pie (Top 10 Locations)\n",
    "if 'loc_counts' in globals():\n",
    "    top10 = loc_counts.head(10)\n",
    "    other = loc_counts[10:].sum() if len(loc_counts) > 10 else 0\n",
    "    if other > 0:\n",
    "        pie_data = pd.concat([top10, pd.Series({'Others': other})])\n",
    "    else:\n",
    "        pie_data = top10\n",
    "    plot_name = \"Sample Distribution (Top 10)\"\n",
    "    plot_params = {\n",
    "        \"top_location\": loc_counts.idxmax(),\n",
    "        \"top_share_pct\": float(loc_counts.max()/loc_counts.sum()*100),\n",
    "        \"n_locations\": int(len(loc_counts)),\n",
    "    }\n",
    "    data_notes = {\n",
    "        \"top10_counts\": {k: int(v) for k, v in top10.to_dict().items()},\n",
    "        \"others\": int(other),\n",
    "    }\n",
    "    print(\"Params:\", plot_params)\n",
    "    plt.figure(figsize=(7, 7))\n",
    "    plt.pie(\n",
    "        pie_data.values,\n",
    "        labels=pie_data.index,\n",
    "        autopct='%1.1f%%',\n",
    "        startangle=90,\n",
    "        textprops={'fontsize': 9},\n",
    "        pctdistance=0.75,\n",
    "        labeldistance=1.05,\n",
    "    )\n",
    "    plt.title(plot_name)\n",
    "    plt.axis('equal')\n",
    "    plt.tight_layout()\n",
    "    log_plot(\n",
    "        name=plot_name,\n",
    "        description=\"T·ª∑ l·ªá m·∫´u top 10 location\",\n",
    "        params=plot_params,\n",
    "        data_notes=data_notes,\n",
    "    )\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Run Cell 3 first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "108b6240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: Signal Quality Prep (select target and compute stats)\n",
    "if 'df_final' in locals():\n",
    "    TARGET_LOC = df_final['location'].value_counts().idxmax()\n",
    "    df_loc = df_final[df_final['location'] == TARGET_LOC]\n",
    "    TARGET_BEACON = df_loc['beacon_id'].value_counts().idxmax()\n",
    "\n",
    "    subset = df_loc[df_loc['beacon_id'] == TARGET_BEACON].copy().sort_values('datetime')\n",
    "    subset['time_diff'] = subset['datetime'].diff().dt.total_seconds()\n",
    "    gaps = subset['time_diff'].dropna()\n",
    "\n",
    "    snr_score = abs(subset['RSSI'].mean()) / subset['RSSI'].std() if subset['RSSI'].std() > 0 else 0\n",
    "    cv = subset['RSSI'].std() / abs(subset['RSSI'].mean()) if subset['RSSI'].mean() != 0 else np.inf\n",
    "    stability_index = 1 / cv if cv > 0 else 0\n",
    "\n",
    "    top_locs_for_beacon = df_final[df_final['beacon_id'] == TARGET_BEACON]['location'].value_counts().head(5).index\n",
    "    subset_multi = df_final[(df_final['location'].isin(top_locs_for_beacon)) & (df_final['beacon_id'] == TARGET_BEACON)]\n",
    "\n",
    "    loc_stats = []\n",
    "    for loc in top_locs_for_beacon:\n",
    "        loc_data = subset_multi[subset_multi['location'] == loc]['RSSI']\n",
    "        loc_stats.append({\n",
    "            'location': loc,\n",
    "            'mean_rssi': loc_data.mean(),\n",
    "            'std_rssi': loc_data.std(),\n",
    "            'snr': abs(loc_data.mean()) / loc_data.std() if loc_data.std() > 0 else 0,\n",
    "            'count': len(loc_data)\n",
    "        })\n",
    "    df_loc_stats = pd.DataFrame(loc_stats).sort_values('snr', ascending=False)\n",
    "\n",
    "    print(\"SIGNAL PREP\")\n",
    "    print(f\"Target location={TARGET_LOC}, beacon={TARGET_BEACON}\")\n",
    "    print(f\"SNR={snr_score:.2f}, CV={cv:.3f}, StabilityIndex={stability_index:.2f}, Samples={len(subset):,}\")\n",
    "    print(f\"Gaps>10s: {len(gaps[gaps > 10])}/{len(gaps)}\")\n",
    "else:\n",
    "    print(\"Run Cell 2 first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b744a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 13: Plot - RSSI Time Series (Target location/beacon)\n",
    "if 'subset' in globals():\n",
    "    plot_name = f\"RSSI Time Series (Loc {TARGET_LOC}, Beacon {TARGET_BEACON})\"\n",
    "    plot_params = {\n",
    "        \"mean\": float(subset['RSSI'].mean()),\n",
    "        \"std\": float(subset['RSSI'].std()),\n",
    "        \"samples\": int(len(subset)),\n",
    "    }\n",
    "    data_notes = {\n",
    "        \"time_start\": str(subset['datetime'].min()),\n",
    "        \"time_end\": str(subset['datetime'].max()),\n",
    "    }\n",
    "    print(\"Params:\", plot_params)\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.plot(subset['datetime'], subset['RSSI'], marker='o', linestyle='-', markersize=1, alpha=0.4, color='blue', label='Raw RSSI')\n",
    "    subset['rssi_smooth'] = subset['RSSI'].rolling(window=10, center=True).mean()\n",
    "    plt.plot(subset['datetime'], subset['rssi_smooth'], color='red', linewidth=2, label='Rolling Mean (10)')\n",
    "    plt.axhline(subset['RSSI'].mean(), color='green', linestyle='--', label=f\"Mean {subset['RSSI'].mean():.1f}\")\n",
    "    plt.fill_between(subset['datetime'], subset['RSSI'].mean() - subset['RSSI'].std(), subset['RSSI'].mean() + subset['RSSI'].std(), alpha=0.2, color='green', label='¬±1 Std')\n",
    "    plt.ylabel(\"RSSI (dBm)\")\n",
    "    plt.title(plot_name)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    log_plot(\n",
    "        name=plot_name,\n",
    "        description=\"RSSI theo th·ªùi gian cho location/beacon ti√™u bi·ªÉu\",\n",
    "        params=plot_params,\n",
    "        data_notes=data_notes,\n",
    "    )\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Run Cell 12 first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca3240bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 14: Plot - RSSI Distribution (Target)\n",
    "if 'subset' in globals():\n",
    "    plot_name = \"RSSI Distribution\"\n",
    "    plot_params = {\n",
    "        \"mean\": float(subset['RSSI'].mean()),\n",
    "        \"median\": float(subset['RSSI'].median()),\n",
    "        \"samples\": int(len(subset)),\n",
    "    }\n",
    "    data_notes = {\n",
    "        \"quartiles\": {\n",
    "            \"q25\": float(subset['RSSI'].quantile(0.25)),\n",
    "            \"q75\": float(subset['RSSI'].quantile(0.75)),\n",
    "        }\n",
    "    }\n",
    "    print(\"Params:\", plot_params)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.hist(subset['RSSI'], bins=30, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "    plt.axvline(subset['RSSI'].mean(), color='red', linestyle='--', linewidth=2, label='Mean')\n",
    "    plt.axvline(subset['RSSI'].median(), color='orange', linestyle='--', linewidth=2, label='Median')\n",
    "    plt.xlabel(\"RSSI (dBm)\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(plot_name)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    log_plot(\n",
    "        name=plot_name,\n",
    "        description=\"Ph√¢n ph·ªëi RSSI cho location/beacon m·ª•c ti√™u\",\n",
    "        params=plot_params,\n",
    "        data_notes=data_notes,\n",
    "    )\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Run Cell 12 first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01f184be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 15: Plot - Time Gap Distribution (<60s)\n",
    "if 'gaps' in globals():\n",
    "    gaps_filtered = gaps[gaps < 60]\n",
    "    plot_name = \"Time Gap Distribution (<60s)\"\n",
    "    plot_params = {\n",
    "        \"median_gap_sec\": float(gaps_filtered.median()),\n",
    "        \"mean_gap_sec\": float(gaps_filtered.mean()),\n",
    "        \"count\": int(len(gaps_filtered)),\n",
    "    }\n",
    "    data_notes = {\n",
    "        \"max_gap_sec\": float(gaps_filtered.max()) if len(gaps_filtered) else None,\n",
    "    }\n",
    "    print(\"Params:\", plot_params)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.hist(gaps_filtered, bins=40, color='orange', edgecolor='black', alpha=0.7)\n",
    "    plt.axvline(gaps_filtered.median(), color='red', linestyle='--', linewidth=2, label='Median')\n",
    "    plt.xlabel(\"Gap (s)\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(plot_name)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    log_plot(\n",
    "        name=plot_name,\n",
    "        description=\"Ph√¢n ph·ªëi kho·∫£ng c√°ch th·ªùi gian ƒëo RSSI (<60s)\",\n",
    "        params=plot_params,\n",
    "        data_notes=data_notes,\n",
    "    )\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Run Cell 12 first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f50c661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 16: Plot - RSSI Boxplot Across Locations (Target Beacon)\n",
    "if 'subset_multi' in globals():\n",
    "    plot_name = f\"RSSI Distribution Across Locations (Beacon {TARGET_BEACON})\"\n",
    "    plot_params = {\n",
    "        \"beacon\": TARGET_BEACON,\n",
    "        \"locations\": int(subset_multi['location'].nunique()),\n",
    "    }\n",
    "    data_notes = {\n",
    "        \"samples_per_location\": subset_multi['location'].value_counts().head(5).to_dict(),\n",
    "    }\n",
    "    print(\"Params:\", plot_params)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.boxplot(data=subset_multi, x='location', y='RSSI', palette=\"Set2\")\n",
    "    plt.xlabel(\"Location\")\n",
    "    plt.ylabel(\"RSSI (dBm)\")\n",
    "    plt.title(plot_name)\n",
    "    plt.xticks(rotation=30, ha='right')\n",
    "    plt.gcf().subplots_adjust(bottom=0.3)\n",
    "    plt.tight_layout()\n",
    "    log_plot(\n",
    "        name=plot_name,\n",
    "        description=\"So s√°nh ph√¢n ph·ªëi RSSI theo location cho beacon m·ª•c ti√™u\",\n",
    "        params=plot_params,\n",
    "        data_notes=data_notes,\n",
    "    )\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Run Cell 12 first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6423cd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 17: Plot - SNR Comparison (Target Beacon)\n",
    "if 'df_loc_stats' in globals():\n",
    "    plot_name = f\"SNR Comparison (Beacon {TARGET_BEACON})\"\n",
    "    plot_params = {\n",
    "        \"snr_threshold\": 5,\n",
    "        \"locations\": df_loc_stats['location'].tolist(),\n",
    "    }\n",
    "    data_notes = {\n",
    "        \"snr_list\": df_loc_stats['snr'].round(2).tolist(),\n",
    "    }\n",
    "    print(\"Params:\", plot_params)\n",
    "    plt.figure(figsize=(9, 5))\n",
    "    sns.barplot(y=df_loc_stats['location'], x=df_loc_stats['snr'], color='seagreen')\n",
    "    plt.axvline(5, color='gray', linestyle='--', linewidth=1, label='Threshold=5')\n",
    "    plt.xlabel(\"SNR (Mean/Std)\")\n",
    "    plt.ylabel(\"Location\")\n",
    "    plt.title(plot_name)\n",
    "    plt.legend()\n",
    "    plt.gcf().subplots_adjust(left=0.3)\n",
    "    plt.tight_layout()\n",
    "    log_plot(\n",
    "        name=plot_name,\n",
    "        description=\"So s√°nh SNR gi·ªØa c√°c location cho beacon m·ª•c ti√™u\",\n",
    "        params=plot_params,\n",
    "        data_notes=data_notes,\n",
    "    )\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Run Cell 12 first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "09c4191d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 18: Feature Engineering - Sliding Window Aggregation\n",
    "# Kh·ª≠ nhi·ªÖu v√† t·∫°o features ·ªïn ƒë·ªãnh h∆°n b·∫±ng Sliding Window.\n",
    "\n",
    "if 'df_final' in locals():\n",
    "    print(\"Running Sliding Window (window=5s)\")\n",
    "\n",
    "    WINDOW_SIZE = '5s'\n",
    "    windowed_list = []\n",
    "\n",
    "    for loc in tqdm(sorted(df_final['location'].unique()), desc=\"Processing Locations\"):\n",
    "        df_loc = df_final[df_final['location'] == loc].copy()\n",
    "        df_loc = df_loc.groupby(['datetime', 'beacon_id'], as_index=False)['RSSI'].mean()\n",
    "        df_pivot = df_loc.pivot(index='datetime', columns='beacon_id', values='RSSI')\n",
    "        df_resampled = df_pivot.resample(WINDOW_SIZE).mean()\n",
    "        df_resampled = df_resampled.dropna(how='all')\n",
    "        df_resampled = df_resampled.fillna(-100)\n",
    "        df_resampled = df_resampled.reset_index(drop=True)\n",
    "        df_resampled['location'] = loc\n",
    "        windowed_list.append(df_resampled)\n",
    "\n",
    "    df_windowed = pd.concat(windowed_list, ignore_index=True)\n",
    "\n",
    "    for b_id in BEACON_IDS:\n",
    "        if b_id not in df_windowed.columns:\n",
    "            df_windowed[b_id] = -100\n",
    "\n",
    "    df_windowed = df_windowed.fillna(-100)\n",
    "    cols_ordered = sorted([c for c in df_windowed.columns if c != 'location'], key=lambda x: int(x)) + ['location']\n",
    "    df_windowed = df_windowed[cols_ordered]\n",
    "\n",
    "    print(\"Feature Engineering DONE\")\n",
    "    print(f\"Shape: {df_windowed.shape}\")\n",
    "    display(df_windowed.head(5))\n",
    "\n",
    "    print(\"\\nFEATURE ENGINEERING REPORT\")\n",
    "    print(f\"Original Raw Samples: {len(df_final):,}\")\n",
    "    print(f\"Windowed Samples (5s): {len(df_windowed):,}\")\n",
    "    print(f\"Compression Ratio: {len(df_final)/len(df_windowed):.1f}x\")\n",
    "    print(f\"NaN Count: {df_windowed.isna().sum().sum()}\")\n",
    "    print(f\"All 25 Beacons Present: {len([c for c in df_windowed.columns if c != 'location']) == 25}\")\n",
    "    print(f\"Locations: {df_windowed['location'].nunique()}\")\n",
    "else:\n",
    "    print(\"Run Cell 2 first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2545c98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 19: Advanced Feature Analysis (PCA, t-SNE, Correlation)\n",
    "# ƒê√°nh gi√° kh·∫£ nƒÉng ph√¢n t√°ch d·ªØ li·ªáu sau Feature Engineering.\n",
    "\n",
    "if 'df_windowed' in locals():\n",
    "    from sklearn.decomposition import PCA\n",
    "    from sklearn.manifold import TSNE\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    print(\"Advanced Feature Analysis...\")\n",
    "\n",
    "    feature_cols = [c for c in df_windowed.columns if c != 'location']\n",
    "    X = df_windowed[feature_cols]\n",
    "    y = df_windowed['location']\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Plot 1: Correlation Matrix\n",
    "    corr_matrix = X.corr()\n",
    "    plot_name_corr = \"Beacon Correlation Matrix\"\n",
    "    plot_params_corr = {\n",
    "        \"rows\": int(corr_matrix.shape[0]),\n",
    "        \"cols\": int(corr_matrix.shape[1]),\n",
    "    }\n",
    "    data_notes_corr = {\n",
    "        \"sample_corr\": corr_matrix.iloc[:3, :3].round(2).to_dict(),\n",
    "    }\n",
    "    print(\"Params: corr_matrix shape {}\".format(corr_matrix.shape))\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(corr_matrix, cmap='coolwarm', vmin=-1, vmax=1, center=0, square=True, cbar_kws={\"shrink\": 0.75})\n",
    "    plt.title(plot_name_corr)\n",
    "    plt.tight_layout()\n",
    "    log_plot(\n",
    "        name=plot_name_corr,\n",
    "        description=\"Ma tr·∫≠n t∆∞∆°ng quan gi·ªØa c√°c beacon\",\n",
    "        params=plot_params_corr,\n",
    "        data_notes=data_notes_corr,\n",
    "    )\n",
    "    plt.show()\n",
    "\n",
    "    # Plot 2: Variance per Beacon\n",
    "    variances = X.var().sort_values(ascending=False)\n",
    "    plot_name_var = \"Beacon Variance\"\n",
    "    plot_params_var = {\n",
    "        \"top5_variances\": variances.head(5).round(2).tolist(),\n",
    "    }\n",
    "    data_notes_var = {\n",
    "        \"bottom5_variances\": variances.tail(5).round(2).tolist(),\n",
    "    }\n",
    "    print(\"Params: top5 variances={}\".format(variances.head(5).round(2).tolist()))\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    sns.barplot(x=variances.index, y=variances.values, palette='viridis')\n",
    "    plt.ylabel('Variance')\n",
    "    plt.xlabel('Beacon ID')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.gcf().subplots_adjust(bottom=0.3)\n",
    "    plt.title(plot_name_var)\n",
    "    plt.tight_layout()\n",
    "    log_plot(\n",
    "        name=plot_name_var,\n",
    "        description=\"Ph∆∞∆°ng sai theo beacon sau resample\",\n",
    "        params=plot_params_var,\n",
    "        data_notes=data_notes_var,\n",
    "    )\n",
    "    plt.show()\n",
    "\n",
    "    # Plot 3: PCA scatter\n",
    "    print(\"Running PCA...\")\n",
    "    pca = PCA(n_components=2)\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "    explained_total = float(pca.explained_variance_ratio_.sum())\n",
    "    plot_name_pca = \"PCA Scatter (2D)\"\n",
    "    plot_params_pca = {\n",
    "        \"explained_total\": explained_total,\n",
    "        \"pc1\": float(pca.explained_variance_ratio_[0]),\n",
    "        \"pc2\": float(pca.explained_variance_ratio_[1]),\n",
    "    }\n",
    "    data_notes_pca = {\n",
    "        \"num_samples\": int(len(X_scaled)),\n",
    "        \"num_locations\": int(y.nunique()),\n",
    "    }\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.scatterplot(x=X_pca[:,0], y=X_pca[:,1], hue=y, palette='tab20', s=40, alpha=0.6, legend=False)\n",
    "    plt.title(f'PCA (Explained Var: {explained_total:.2%})')\n",
    "    plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%})')\n",
    "    plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%})')\n",
    "    plt.tight_layout()\n",
    "    log_plot(\n",
    "        name=plot_name_pca,\n",
    "        description=\"PCA 2D sau chu·∫©n h√≥a StandardScaler\",\n",
    "        params=plot_params_pca,\n",
    "        data_notes=data_notes_pca,\n",
    "    )\n",
    "    plt.show()\n",
    "\n",
    "    # Plot 4: t-SNE scatter\n",
    "    print(\"Running t-SNE...\")\n",
    "    tsne = TSNE(n_components=2, perplexity=30, random_state=42, n_jobs=-1)\n",
    "    X_tsne = tsne.fit_transform(X_scaled)\n",
    "    plot_name_tsne = \"t-SNE (Manifold Structure)\"\n",
    "    plot_params_tsne = {\n",
    "        \"perplexity\": 30,\n",
    "        \"samples\": int(len(X_scaled)),\n",
    "    }\n",
    "    data_notes_tsne = {\n",
    "        \"num_locations\": int(y.nunique()),\n",
    "    }\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.scatterplot(x=X_tsne[:,0], y=X_tsne[:,1], hue=y, palette='tab20', s=40, alpha=0.6, legend=False)\n",
    "    plt.title(plot_name_tsne)\n",
    "    plt.tight_layout()\n",
    "    log_plot(\n",
    "        name=plot_name_tsne,\n",
    "        description=\"t-SNE 2D ƒë·ªÉ quan s√°t manifold\",\n",
    "        params=plot_params_tsne,\n",
    "        data_notes=data_notes_tsne,\n",
    "    )\n",
    "    plt.show()\n",
    "\n",
    "    # Report\n",
    "    high_corr_pairs = []\n",
    "    corr_mat_abs = corr_matrix.abs()\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i+1, len(corr_matrix.columns)):\n",
    "            if corr_mat_abs.iloc[i, j] > 0.8:\n",
    "                high_corr_pairs.append(f\"{corr_matrix.columns[i]}-{corr_matrix.columns[j]} ({corr_matrix.iloc[i, j]:.2f})\")\n",
    "\n",
    "    low_var_beacons = variances[variances < 10].index.tolist()\n",
    "\n",
    "    print(\"ANALYSIS SUMMARY\")\n",
    "    print(f\"High-corr pairs (>0.8): {len(high_corr_pairs)}\")\n",
    "    if high_corr_pairs:\n",
    "        print(f\"Examples: {', '.join(high_corr_pairs[:5])}\")\n",
    "    print(f\"Low-variance beacons (<10): {low_var_beacons}\")\n",
    "    print(f\"PCA explained variance: {pca.explained_variance_ratio_.sum():.2%}\")\n",
    "else:\n",
    "    print(\"Run Cell 18 first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec747d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 20: Extended Feature Engineering - Robust stats, coverage, delta\n",
    "# T·∫°o ƒë·∫∑c tr∆∞ng b·ªÅn v·ªØng h∆°n cho c·ª≠a s·ªï 5s: median, IQR, packet count, coverage flag, delta median.\n",
    "\n",
    "if 'df_final' in locals():\n",
    "    print(\"Extended Sliding Window (window=5s) with robust stats\")\n",
    "\n",
    "    WINDOW_SIZE = '5s'\n",
    "    DEFAULT_RSSI = -110\n",
    "\n",
    "    def iqr(x: pd.Series) -> float:\n",
    "        return float(x.quantile(0.75) - x.quantile(0.25))\n",
    "\n",
    "    def ensure_cols(wide: pd.DataFrame, fill_val: float) -> pd.DataFrame:\n",
    "        for b in BEACON_IDS:\n",
    "            if b not in wide.columns:\n",
    "                wide[b] = fill_val\n",
    "        wide = wide[sorted(wide.columns, key=lambda x: int(x))]\n",
    "        return wide.fillna(fill_val)\n",
    "\n",
    "    extended_list = []\n",
    "\n",
    "    for loc in tqdm(sorted(df_final['location'].unique()), desc=\"Processing Locations (extended)\"):\n",
    "        df_loc = df_final[df_final['location'] == loc][['datetime', 'beacon_id', 'RSSI']].copy()\n",
    "        df_loc = df_loc.set_index('datetime')\n",
    "\n",
    "        agg = df_loc.groupby('beacon_id').resample(WINDOW_SIZE)['RSSI'].agg(['mean', 'median', 'count', iqr])\n",
    "        if agg.empty:\n",
    "            continue\n",
    "        agg = agg.reset_index()\n",
    "\n",
    "        def to_wide(col: str) -> pd.DataFrame:\n",
    "            wide = agg.pivot(index='datetime', columns='beacon_id', values=col)\n",
    "            wide.index = pd.to_datetime(wide.index)\n",
    "            return wide\n",
    "\n",
    "        mean_w = to_wide('mean')\n",
    "        median_w = to_wide('median')\n",
    "        iqr_w = to_wide('iqr')\n",
    "        count_w = to_wide('count')\n",
    "\n",
    "        mean_w = ensure_cols(mean_w, DEFAULT_RSSI)\n",
    "        median_w = ensure_cols(median_w, DEFAULT_RSSI)\n",
    "        iqr_w = ensure_cols(iqr_w, 0.0)\n",
    "        count_w = ensure_cols(count_w, 0.0)\n",
    "\n",
    "        cov_w = (count_w > 0).astype(int)\n",
    "        valid_mask = cov_w.sum(axis=1) > 0\n",
    "        if valid_mask.sum() == 0:\n",
    "            continue\n",
    "\n",
    "        mean_w = mean_w.loc[valid_mask]\n",
    "        median_w = median_w.loc[valid_mask]\n",
    "        iqr_w = iqr_w.loc[valid_mask]\n",
    "        count_w = count_w.loc[valid_mask]\n",
    "        cov_w = cov_w.loc[valid_mask]\n",
    "\n",
    "        delta_median = median_w.diff().fillna(0)\n",
    "\n",
    "        df_feat = pd.concat([\n",
    "            mean_w.add_prefix('b').add_suffix('_mean'),\n",
    "            median_w.add_prefix('b').add_suffix('_median'),\n",
    "            iqr_w.add_prefix('b').add_suffix('_iqr'),\n",
    "            count_w.add_prefix('b').add_suffix('_count'),\n",
    "            cov_w.add_prefix('b').add_suffix('_cov'),\n",
    "            delta_median.add_prefix('b').add_suffix('_dmedian'),\n",
    "        ], axis=1)\n",
    "        df_feat['location'] = loc\n",
    "        df_feat = df_feat.reset_index(drop=True)\n",
    "        extended_list.append(df_feat)\n",
    "\n",
    "    if extended_list:\n",
    "        df_windowed_ext = pd.concat(extended_list, ignore_index=True)\n",
    "        feature_cols = [c for c in df_windowed_ext.columns if c != 'location']\n",
    "        print(\"Extended Feature Engineering DONE\")\n",
    "        print(f\"Shape: {df_windowed_ext.shape}\")\n",
    "        print(f\"Columns: {len(feature_cols)} feature cols + location\")\n",
    "        print(f\"Raw samples: {len(df_final):,}; Windows (5s): {len(df_windowed_ext):,}\")\n",
    "        print(f\"Compression: {len(df_final)/len(df_windowed_ext):.1f}x\")\n",
    "        print(f\"NaN Count: {df_windowed_ext.isna().sum().sum()}\")\n",
    "        print(f\"Locations: {df_windowed_ext['location'].nunique()}\")\n",
    "        display(df_windowed_ext.head(3))\n",
    "    else:\n",
    "        print(\"No extended windows produced.\")\n",
    "else:\n",
    "    print(\"Run Cell 2 first.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9ac21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 21: EDA cho feature m·ªü r·ªông (median/IQR/count/coverage/delta)\n",
    "if 'df_windowed_ext' in locals():\n",
    "    cov_cols = [c for c in df_windowed_ext.columns if c.endswith('_cov')]\n",
    "    median_cols = [c for c in df_windowed_ext.columns if c.endswith('_median')]\n",
    "    iqr_cols = [c for c in df_windowed_ext.columns if c.endswith('_iqr')]\n",
    "    count_cols = [c for c in df_windowed_ext.columns if c.endswith('_count')]\n",
    "    delta_cols = [c for c in df_windowed_ext.columns if c.endswith('_dmedian')]\n",
    "\n",
    "    print(\"EXT FEATURE SUMMARY\")\n",
    "    print(f\"Rows: {len(df_windowed_ext):,}; Feature cols: {len(df_windowed_ext.columns)-1}\")\n",
    "    print(f\"Median cols: {len(median_cols)}, IQR cols: {len(iqr_cols)}, Count cols: {len(count_cols)}, Coverage cols: {len(cov_cols)}, Delta cols: {len(delta_cols)}\")\n",
    "\n",
    "    # Coverage heatmap (% window c√≥ beacon)\n",
    "    coverage_matrix = df_windowed_ext.groupby('location')[cov_cols].mean() * 100\n",
    "    coverage_matrix = coverage_matrix.sort_index()\n",
    "    coverage_matrix.columns = [c.replace('b', '').replace('_cov', '') for c in coverage_matrix.columns]\n",
    "\n",
    "    plot_name_cov = \"Coverage Heatmap (Beacon vs Location, % windows seen)\"\n",
    "    plot_params_cov = {\n",
    "        \"locations\": int(coverage_matrix.shape[0]),\n",
    "        \"beacons\": int(coverage_matrix.shape[1]),\n",
    "        \"min_pct\": float(coverage_matrix.min().min()),\n",
    "        \"max_pct\": float(coverage_matrix.max().max()),\n",
    "    }\n",
    "    data_notes_cov = {\n",
    "        \"zero_pairs\": int((coverage_matrix == 0).sum().sum()),\n",
    "    }\n",
    "    print(\"Params (coverage heatmap):\", plot_params_cov)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.heatmap(coverage_matrix, cmap='YlGnBu', vmin=0, vmax=100, cbar_kws={\"label\": \"% windows with signal\"})\n",
    "    plt.title(plot_name_cov)\n",
    "    plt.xlabel(\"Beacon ID\")\n",
    "    plt.ylabel(\"Location\")\n",
    "    plt.tight_layout()\n",
    "    log_plot(\n",
    "        name=plot_name_cov,\n",
    "        description=\"T·ªâ l·ªá % c·ª≠a s·ªï 5s c√≥ nh·∫≠n g√≥i t·ª´ t·ª´ng beacon theo location\",\n",
    "        params=plot_params_cov,\n",
    "        data_notes=data_notes_cov,\n",
    "    )\n",
    "    plt.show()\n",
    "\n",
    "    # Median RSSI theo beacon (trung b√¨nh tr√™n to√†n b·ªô c·ª≠a s·ªï)\n",
    "    beacon_ids = [c.replace('b', '').replace('_median', '') for c in median_cols]\n",
    "    median_mean = pd.Series({bid: df_windowed_ext[f\"b{bid}_median\"].mean() for bid in beacon_ids})\n",
    "    plot_name_median = \"Median RSSI by Beacon (5s window)\"\n",
    "    plot_params_median = {\n",
    "        \"beacons\": len(median_mean),\n",
    "        \"global_mean\": float(median_mean.mean()),\n",
    "        \"global_min\": float(median_mean.min()),\n",
    "        \"global_max\": float(median_mean.max()),\n",
    "    }\n",
    "    data_notes_median = {\n",
    "        \"lowest3\": median_mean.nsmallest(3).round(2).to_dict(),\n",
    "        \"highest3\": median_mean.nlargest(3).round(2).to_dict(),\n",
    "    }\n",
    "    print(\"Params (median bar):\", plot_params_median)\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    sns.barplot(x=median_mean.index, y=median_mean.values, palette='magma')\n",
    "    plt.axhline(median_mean.mean(), color='red', linestyle='--', linewidth=1, label=f\"Mean: {median_mean.mean():.2f}\")\n",
    "    plt.ylabel(\"Median RSSI (dBm)\")\n",
    "    plt.xlabel(\"Beacon ID\")\n",
    "    plt.title(plot_name_median)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    log_plot(\n",
    "        name=plot_name_median,\n",
    "        description=\"Gi√° tr·ªã median RSSI trung b√¨nh theo beacon (5s window)\",\n",
    "        params=plot_params_median,\n",
    "        data_notes=data_notes_median,\n",
    "    )\n",
    "    plt.show()\n",
    "\n",
    "    # Packet count per beacon (5s window)\n",
    "    count_mean = pd.Series({c.replace('b', '').replace('_count', ''): df_windowed_ext[c].mean() for c in count_cols})\n",
    "    plot_name_count = \"Packet Count per Beacon (5s window)\"\n",
    "    plot_params_count = {\n",
    "        \"beacons\": len(count_mean),\n",
    "        \"mean_packets\": float(count_mean.mean()),\n",
    "        \"min_packets\": float(count_mean.min()),\n",
    "        \"max_packets\": float(count_mean.max()),\n",
    "    }\n",
    "    data_notes_count = {\n",
    "        \"lowest3\": count_mean.nsmallest(3).round(2).to_dict(),\n",
    "        \"highest3\": count_mean.nlargest(3).round(2).to_dict(),\n",
    "    }\n",
    "    print(\"Params (count bar):\", plot_params_count)\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    sns.barplot(x=count_mean.index, y=count_mean.values, palette='viridis')\n",
    "    plt.axhline(count_mean.mean(), color='red', linestyle='--', linewidth=1, label=f\"Mean: {count_mean.mean():.2f}\")\n",
    "    plt.ylabel(\"Packets per 5s window\")\n",
    "    plt.xlabel(\"Beacon ID\")\n",
    "    plt.title(plot_name_count)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    log_plot(\n",
    "        name=plot_name_count,\n",
    "        description=\"S·ªë g√≥i trung b√¨nh m·ªói 5s theo beacon\",\n",
    "        params=plot_params_count,\n",
    "        data_notes=data_notes_count,\n",
    "    )\n",
    "    plt.show()\n",
    "\n",
    "    # Ph∆∞∆°ng sai & t∆∞∆°ng quan tr√™n median features\n",
    "    median_frame = df_windowed_ext[median_cols]\n",
    "    median_var = median_frame.var()\n",
    "    low_var_beacons = median_var.nsmallest(5)\n",
    "    corr_median = median_frame.corr().abs()\n",
    "    high_corr_pairs = []\n",
    "    for i in range(len(corr_median.columns)):\n",
    "        for j in range(i + 1, len(corr_median.columns)):\n",
    "            val = corr_median.iloc[i, j]\n",
    "            if val > 0.8:\n",
    "                high_corr_pairs.append((corr_median.columns[i], corr_median.columns[j], float(val)))\n",
    "\n",
    "    print(\"LOW VARIANCE (median) - bottom 5 beacons:\")\n",
    "    print(low_var_beacons.round(3))\n",
    "    print(f\"High-corr pairs (>0.8): {len(high_corr_pairs)}; examples: {high_corr_pairs[:5]}\")\n",
    "\n",
    "    # Delta stats\n",
    "    delta_abs = df_windowed_ext[delta_cols].abs()\n",
    "    print(\"Delta median summary (abs): mean={:.3f}, max={:.3f}\".format(delta_abs.mean().mean(), delta_abs.max().max()))\n",
    "else:\n",
    "    print(\"Run extended feature cell first.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f30c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 22: L∆∞u b·ªô feature m·ªü r·ªông (CSV + Parquet)\n",
    "if 'df_windowed_ext' in locals():\n",
    "    export_parquet = os.path.join(OUTPUT_PATH, \"df_windowed_ext.parquet\")\n",
    "    export_csv = os.path.join(OUTPUT_PATH, \"df_windowed_ext.csv\")\n",
    "\n",
    "    df_windowed_ext.to_parquet(export_parquet, index=False)\n",
    "    df_windowed_ext.to_csv(export_csv, index=False)\n",
    "\n",
    "    print(\"EXPORTED EXTENDED FEATURES\")\n",
    "    print(f\"Parquet: {export_parquet}\")\n",
    "    print(f\"CSV: {export_csv}\")\n",
    "    print(f\"Shape: {df_windowed_ext.shape}; Columns: {len(df_windowed_ext.columns)-1} feature cols + location\")\n",
    "else:\n",
    "    print(\"Run extended feature cell first.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5efc571",
   "metadata": {},
   "source": [
    "# Cell 23: Ghi ch√∫ b∆∞·ªõc ti·∫øp theo (kh√¥ng th·ª±c thi)\n",
    "- Chia time-based split (vd: 70/15/15 theo th·ªùi gian ho·∫∑c leave-one-trace-out) ƒë·ªÉ tr√°nh leakage.\n",
    "- Hu·∫•n luy·ªán theo Decoupled Training: backbone tr√™n ph√¢n b·ªë g·ªëc, head v·ªõi sampler c√¢n b·∫±ng.\n",
    "- D√πng Class-Balanced Focal (Œ≤‚âà0.999, Œ≥‚àà[0.5,2]) ho·∫∑c LDAM-DRW giai ƒëo·∫°n fine-tune head.\n",
    "- Stress test: dropout 1‚Äì3 beacon m·∫°nh + th√™m nhi·ªÖu Gaussian (œÉ‚âà3‚Äì5 dB) tr√™n t·∫≠p validation ƒë·ªÉ ki·ªÉm tra ƒë·ªô b·ªÅn Macro-F1.\n",
    "- ∆Øu ti√™n baseline XGBoost/LightGBM tr√™n feature m·ªü r·ªông; n·∫øu c·∫ßn temporal s√¢u h∆°n th·ª≠ 1D-CNN/TCN, mask beacons v·∫Øng b·∫±ng coverage flag.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
